# Docker Compose for Oikotie Daily Scraper Automation
# Standalone container deployment with multi-city support

version: '3.8'

services:
  scraper:
    build:
      context: .
      target: production
    container_name: oikotie-scraper
    restart: unless-stopped
    environment:
      - ENVIRONMENT=production
      - DEPLOYMENT_TYPE=container
      - HEADLESS_BROWSER=true
      - HEALTH_CHECK_ENABLED=true
      - DATABASE_PATH=/data/real_estate.duckdb
      - LOG_LEVEL=INFO
      - MAX_WORKERS=5
      - GRACEFUL_SHUTDOWN_TIMEOUT=30
      - MULTI_CITY_ENABLED=true
      - ENABLE_CITY_METRICS=true
      - BACKUP_ENABLED=true
      - BACKUP_RETENTION_DAYS=7
      - CITY_SPECIFIC_ALERTING=true
      - DISASTER_RECOVERY_ENABLED=true
      - BACKUP_ENCRYPTION_ENABLED=true
      - HEALTH_CHECK_CITIES=Helsinki,Espoo
      - METRICS_EXPORT_INTERVAL=30
      - ALERT_WEBHOOK_URL=${ALERT_WEBHOOK_URL:-}
      - BACKUP_S3_BUCKET=${BACKUP_S3_BUCKET:-}
      - BACKUP_S3_REGION=${BACKUP_S3_REGION:-us-east-1}
      - CITY_COORDINATION_ENABLED=true
      - CROSS_CITY_VALIDATION=true
      - MULTI_CITY_BACKUP_STRATEGY=separate
      - CITY_FAILOVER_ENABLED=true
      - GEOSPATIAL_VALIDATION_STRICT=true
    volumes:
      # Data persistence
      - scraper_data:/data
      - scraper_logs:/logs
      - scraper_output:/output
      - scraper_backups:/backups
      # Configuration
      - ./config:/app/config:ro
    ports:
      - "8080:8080"  # Health check endpoint
      - "9090:9090"  # Metrics endpoint (optional)
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Production monitoring stack
  prometheus:
    image: prom/prometheus:latest
    container_name: oikotie-prometheus
    restart: unless-stopped
    depends_on:
      - scraper
    ports:
      - "9090:9090"
    volumes:
      - prometheus_data:/prometheus
      - ./docker/prometheus:/etc/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    networks:
      - default

  grafana:
    image: grafana/grafana:latest
    container_name: oikotie-grafana
    restart: unless-stopped
    depends_on:
      - prometheus
      - scraper
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-piechart-panel,grafana-worldmap-panel
      - GF_ALERTING_ENABLED=true
      - GF_UNIFIED_ALERTING_ENABLED=true
    volumes:
      - grafana_data:/var/lib/grafana
      - ./docker/grafana/provisioning:/etc/grafana/provisioning
      - ./docker/grafana/dashboards:/etc/grafana/dashboards
    networks:
      - default

  alertmanager:
    image: prom/alertmanager:latest
    container_name: oikotie-alertmanager
    restart: unless-stopped
    ports:
      - "9093:9093"
    volumes:
      - alertmanager_data:/alertmanager
      - ./docker/alertmanager:/etc/alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--web.external-url=http://localhost:9093'
    networks:
      - default

volumes:
  scraper_data:
    driver: local
  scraper_logs:
    driver: local
  scraper_output:
    driver: local
  scraper_backups:
    driver: local
  grafana_data:
    driver: local
  prometheus_data:
    driver: local
  alertmanager_data:
    driver: local

networks:
  default:
    name: oikotie-scraper-network