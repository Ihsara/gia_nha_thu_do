# ConfigMaps for monitoring stack
---
# Prometheus configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: oikotie-scraper
  labels:
    app: prometheus
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s

    rule_files:
      - "/etc/prometheus/alert_rules.yml"

    alerting:
      alertmanagers:
        - static_configs:
            - targets:
              - alertmanager:9093

    scrape_configs:
      # Scraper nodes metrics
      - job_name: 'scraper-nodes'
        kubernetes_sd_configs:
        - role: pod
          namespaces:
            names:
            - oikotie-scraper
        relabel_configs:
        - source_labels: [__meta_kubernetes_pod_label_app]
          action: keep
          regex: oikotie-scraper
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
          action: replace
          target_label: __metrics_path__
          regex: (.+)
        - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
          action: replace
          regex: ([^:]+)(?::\d+)?;(\d+)
          replacement: $1:$2
          target_label: __address__
        - action: labelmap
          regex: __meta_kubernetes_pod_label_(.+)
        - source_labels: [__meta_kubernetes_namespace]
          action: replace
          target_label: kubernetes_namespace
        - source_labels: [__meta_kubernetes_pod_name]
          action: replace
          target_label: kubernetes_pod_name

      # City-specific metrics
      - job_name: 'city-metrics'
        kubernetes_sd_configs:
        - role: pod
          namespaces:
            names:
            - oikotie-scraper
        relabel_configs:
        - source_labels: [__meta_kubernetes_pod_label_app]
          action: keep
          regex: oikotie-scraper
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
          action: replace
          target_label: __metrics_path__
          regex: (.+)
          replacement: /metrics/cities
        - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
          action: replace
          regex: ([^:]+)(?::\d+)?;(\d+)
          replacement: $1:$2
          target_label: __address__

      # Redis monitoring
      - job_name: 'redis'
        kubernetes_sd_configs:
        - role: pod
          namespaces:
            names:
            - oikotie-scraper
        relabel_configs:
        - source_labels: [__meta_kubernetes_pod_label_app]
          action: keep
          regex: redis

      # Kubernetes API server
      - job_name: 'kubernetes-apiservers'
        kubernetes_sd_configs:
        - role: endpoints
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
        - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
          action: keep
          regex: default;kubernetes;https

      # Kubernetes nodes
      - job_name: 'kubernetes-nodes'
        kubernetes_sd_configs:
        - role: node
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)

  alert_rules.yml: |
    groups:
    - name: scraper.rules
      rules:
      # High-level system alerts
      - alert: HighCPUUsage
        expr: avg(rate(process_cpu_seconds_total{job="scraper-nodes"}[5m])) > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage detected"
          description: "CPU usage is above 80% for 5 minutes on {{ $labels.kubernetes_pod_name }}"

      - alert: HighMemoryUsage
        expr: (process_resident_memory_bytes{job="scraper-nodes"} / 1024 / 1024 / 1024) > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage detected"
          description: "Memory usage is above 800MB for 5 minutes on {{ $labels.kubernetes_pod_name }}"

      - alert: ScraperPodDown
        expr: up{job="scraper-nodes"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Scraper pod is down"
          description: "Scraper pod {{ $labels.kubernetes_pod_name }} has been down for more than 1 minute"

    - name: city-specific.rules
      rules:
      # City-specific scraping alerts
      - alert: CityScrapingFailure
        expr: increase(scraper_city_scraping_failures_total{job="city-metrics"}[10m]) > 5
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Scraping failures for {{ $labels.city }}"
          description: "{{ $labels.city }} has experienced {{ $value }} scraping failures in the last 10 minutes"

      - alert: CityScrapingStalled
        expr: time() - scraper_city_last_successful_scrape_timestamp{job="city-metrics"} > 3600
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Scraping stalled for {{ $labels.city }}"
          description: "{{ $labels.city }} hasn't had a successful scrape in over 1 hour"

      - alert: LowGeospatialMatchRate
        expr: scraper_city_geospatial_match_rate{job="city-metrics"} < 0.95
        for: 30m
        labels:
          severity: warning
          threshold: "95%"
        annotations:
          summary: "Low geospatial match rate for {{ $labels.city }}"
          description: "{{ $labels.city }} has a geospatial match rate of {{ $value | humanizePercentage }} (below 95%) for 30 minutes"

---
# Alertmanager configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: oikotie-scraper
  labels:
    app: alertmanager
data:
  alertmanager.yml: |
    global:
      smtp_smarthost: 'localhost:587'
      smtp_from: 'alerts@oikotie-scraper.local'
      resolve_timeout: 5m

    route:
      group_by: ['alertname', 'city']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 1h
      receiver: 'web.hook'
      routes:
      - match:
          severity: critical
        receiver: 'critical-alerts'
        group_wait: 5s
        repeat_interval: 30m
      - match:
          alertname: CityScrapingFailure
        receiver: 'city-specific-alerts'
        group_by: ['city']
        group_wait: 5s
        repeat_interval: 15m

    receivers:
    - name: 'web.hook'
      webhook_configs:
      - url: 'http://webhook-service:5001/webhook'
        send_resolved: true

    - name: 'critical-alerts'
      webhook_configs:
      - url: 'http://webhook-service:5001/webhook/critical'
        send_resolved: true
        title: 'CRITICAL: {{ .GroupLabels.alertname }}'

    - name: 'city-specific-alerts'
      webhook_configs:
      - url: 'http://webhook-service:5001/webhook/city'
        send_resolved: true
        title: 'City Alert: {{ .GroupLabels.city }} - {{ .GroupLabels.alertname }}'

    inhibit_rules:
    - source_match:
        severity: 'critical'
      target_match:
        severity: 'warning'
      equal: ['alertname', 'city', 'kubernetes_pod_name']

---
# Grafana provisioning
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-provisioning
  namespace: oikotie-scraper
  labels:
    app: grafana
data:
  datasources.yml: |
    apiVersion: 1
    datasources:
    - name: Prometheus
      type: prometheus
      access: proxy
      url: http://prometheus:9090
      isDefault: true
      editable: true

  dashboards.yml: |
    apiVersion: 1
    providers:
    - name: 'default'
      orgId: 1
      folder: ''
      type: file
      disableDeletion: false
      updateIntervalSeconds: 10
      allowUiUpdates: true
      options:
        path: /etc/grafana/dashboards

---
# Grafana dashboards
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboards
  namespace: oikotie-scraper
  labels:
    app: grafana
data:
  multi-city-overview.json: |
    {
      "dashboard": {
        "id": null,
        "title": "Multi-City Scraper Overview",
        "tags": ["scraper", "multi-city"],
        "timezone": "browser",
        "panels": [
          {
            "id": 1,
            "title": "Active Cities",
            "type": "stat",
            "targets": [
              {
                "expr": "count(count by (city)(scraper_city_listings_scraped_total))",
                "legendFormat": "Active Cities"
              }
            ],
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0}
          },
          {
            "id": 2,
            "title": "Total Listings by City",
            "type": "bargauge",
            "targets": [
              {
                "expr": "sum by (city)(scraper_city_listings_scraped_total)",
                "legendFormat": "{{ city }}"
              }
            ],
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0}
          },
          {
            "id": 3,
            "title": "Scraping Success Rate by City",
            "type": "timeseries",
            "targets": [
              {
                "expr": "rate(scraper_city_successful_scrapes_total[5m]) / rate(scraper_city_total_scrapes_total[5m])",
                "legendFormat": "{{ city }}"
              }
            ],
            "gridPos": {"h": 8, "w": 24, "x": 0, "y": 8}
          }
        ],
        "time": {"from": "now-1h", "to": "now"},
        "refresh": "30s"
      }
    }