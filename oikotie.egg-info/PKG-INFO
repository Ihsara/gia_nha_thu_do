Metadata-Version: 2.4
Name: oikotie
Version: 0.1.0
Summary: A web scraper and data analysis dashboard for Oikotie.fi.
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.9
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: beautifulsoup4>=4.12.3
Requires-Dist: duckdb>=0.10.0
Requires-Dist: loguru>=0.7.2
Requires-Dist: pandas>=2.2.0
Requires-Dist: selenium>=4.18.0
Requires-Dist: geopy>=2.4.1
Requires-Dist: folium>=0.15.1
Requires-Dist: scipy>=1.12.0
Requires-Dist: branca>=0.7.1
Requires-Dist: geopandas>=0.14.4
Requires-Dist: fiona>=1.9.6
Requires-Dist: contextily>=1.5.0
Requires-Dist: geodatasets>=2023.5.0
Provides-Extra: test
Requires-Dist: pytest>=8.0.0; extra == "test"
Requires-Dist: pytest-mock>=3.12.0; extra == "test"
Dynamic: license-file

# Oikotie Scraper and Dashboard

This project scrapes real estate data from Oikotie.fi, prepares it for analysis, and provides a dashboard for visualization.

## Project Structure

-   `config/`: Contains configuration files.
    -   `config.json`: The main configuration file for the scraper.
-   `data/`: (Ignored by git) Contains the raw and processed data, including the main `real_estate.duckdb` database and open data from the National Land Survey of Finland.
-   `docs/`: Project documentation.
-   `notebooks/`: Jupyter notebooks for data analysis and visualization.
    -   `check_data.ipynb`: For data visualization and quality checks of the scraped data.
    -   `explore_open_data.ipynb`: For visualizing Helsinki properties with a map background. It prioritizes loading data from the database for performance.
    -   `inspect_gml_data.ipynb`: For inspecting the GML data from the `L4134C.zip` file.
-   `oikotie/`: The main Python package containing all source code.
-   `output/`: (Ignored by git) For generated outputs like reports or images (currently unused).
-   `tests/`: Unit and integration tests.
-   `prepare_geospatial_data.py`: A script to process and load large geospatial data into the database, filtered for Helsinki.
-   `prepare_topographic_data.py`: A script to process the topographic data from the `L4134C.zip` file.

## Workflow

The entire data pipeline is managed by a single script.

1.  **Prepare Geospatial Data (Recommended for performance)**:
    Before running the visualization notebook, it is recommended to load the large geospatial data into the database. This only needs to be done once.
    ```sh
    python prepare_geospatial_data.py
    ```

2.  **Prepare Topographic Data (Optional)**:
    To process the topographic data, run the following script:
    ```sh
    python prepare_topographic_data.py
    ```

3.  **Run the full workflow**:
    ```sh
    python run_workflow.py
    ```
    This script executes the following steps in order:
    a.  **Scrape Data**: Fetches the latest listings from Oikotie.fi.
    b.  **Prepare Locations**: Geocodes any new addresses or postal codes.
    c.  **Check Status**: Prints a report on the final state of the database.

4.  **Analyze the Data**:
    Once the workflow is complete, you can use the Jupyter Notebooks to explore the data.
    -   To check the scraped data:
        ```sh
        jupyter lab notebooks/check_data.ipynb
        ```
    -   To visualize Helsinki properties:
        ```sh
        jupyter lab notebooks/explore_open_data.ipynb
        ```
    -   To inspect the GML data:
        ```sh
        jupyter lab notebooks/inspect_gml_data.ipynb
        ```

## Setup and Installation

1.  **Clone the repository.**
2.  **Create and activate a virtual environment:**
    ```sh
    uv venv
    source .venv/bin/activate
    ```
3.  **Install dependencies:**
    ```sh
    uv sync --all-extras
    ```
