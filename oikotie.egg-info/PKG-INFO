Metadata-Version: 2.4
Name: oikotie
Version: 0.1.0
Summary: A web scraper and data analysis dashboard for Oikotie.fi.
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.9
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: beautifulsoup4>=4.12.3
Requires-Dist: duckdb>=0.10.0
Requires-Dist: loguru>=0.7.2
Requires-Dist: pandas>=2.2.0
Requires-Dist: selenium>=4.18.0
Requires-Dist: geopy>=2.4.1
Requires-Dist: folium>=0.15.1
Requires-Dist: scipy>=1.12.0
Requires-Dist: branca>=0.7.1
Requires-Dist: geopandas>=0.14.4
Provides-Extra: test
Requires-Dist: pytest>=8.0.0; extra == "test"
Requires-Dist: pytest-mock>=3.12.0; extra == "test"
Dynamic: license-file

# Oikotie Scraper and Dashboard

This project scrapes real estate data from Oikotie.fi and provides an interactive dashboard to visualize the collected data.

## Setup and Installation

**Prerequisites:**
-   Python 3.9+
-   `uv` installed. If you don't have it: `pip install uv`.

**Installation Steps:**

1.  **Clone the repository and navigate into it.**
2.  **Create and activate a virtual environment:**
    ```sh
    uv venv
    source .venv/bin/activate  # On macOS/Linux
    # .venv\Scripts\activate  # On Windows
    ```
3.  **Install dependencies:**
    ```sh
    uv sync --all-extras
    ```

## Data Preparation (One-Time Setup)

Before running the main workflow, you need to prepare the road network data.

1.  **Download and prepare road data**:
    ```sh
    python prepare_road_data.py
    ```
    This script will download the road network data for the Helsinki region and store it in the database. This only needs to be run once.

## Daily Workflow

The project is designed to be run in a sequence. A wrapper script is provided to execute the entire daily workflow.

1.  **Run the full workflow**:
    ```sh
    python run_workflow.py
    ```
    This script will:
    a.  Scrape the latest listings from Oikotie.fi.
    b.  Update the database with new and changed listings, and mark removed listings as deleted.
    c.  Geocode any new addresses or postal codes to prepare for mapping.
    d.  Provide a status check of the database.

2.  **Analyze the Data**:
    Once the workflow is complete, you can use the Jupyter Notebook to explore the data.
    ```sh
    jupyter lab notebooks/dashboard.ipynb
    ```

## Automation

You can schedule the `run_workflow.py` script to run automatically. See the "Automation" section in `docs/DASHBOARD.md` for instructions on how to set this up for your operating system.
